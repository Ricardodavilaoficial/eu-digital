import openai
import os
import traceback
from services.gcs_handler import montar_contexto_para_pergunta

openai.api_key = os.getenv("OPENAI_API_KEY")

# Hist√≥rico tempor√°rio de conversas recentes
chat_history = []

def obter_resposta_openai(pergunta):
    try:
        print(f"\nüì® Pergunta recebida: {pergunta}")

        # Monta contexto a partir dos arquivos do usu√°rio
        contexto_extra = montar_contexto_para_pergunta(pergunta)
        print(f"üìö Contexto montado: {contexto_extra[:100]}...")  # Mostra apenas os 100 primeiros caracteres

        # Define prompt do "Ricardo digital"
        prompt_base = {
            "role": "system",
            "content": (
                "Voc√™ √© a vers√£o digital do Ricardo, uma c√≥pia fiel de sua mente, mem√≥rias e modo de falar. "
                "Sempre responda em primeira pessoa, como se fosse o pr√≥prio Ricardo. "
                "Use linguagem natural, clara e direta. "
                "Responda de forma curta e objetiva, a menos que o usu√°rio pe√ßa mais detalhes. "
                "Use o contexto abaixo como base de conhecimento:\n\n" + contexto_extra
            )
        }

        # Limpa o hist√≥rico e mant√©m apenas o prompt inicial se houver risco de ultrapassar tokens
        if len(chat_history) > 3:
            chat_history.clear()

        if not chat_history:
            chat_history.append(prompt_base)

        # Adiciona a pergunta do usu√°rio
        chat_history.append({"role": "user", "content": pergunta})

        # Escolhe o modelo: GPT-3.5 por padr√£o, GPT-4 apenas se for um pedido mais elaborado
        usar_gpt_4 = (
            len(pergunta.split()) > 15
            or "detalhe" in pergunta.lower()
            or "explique" in pergunta.lower()
            or "aprofund" in pergunta.lower()
        )
        modelo_escolhido = "gpt-4" if usar_gpt_4 else "gpt-3.5-turbo"
        print(f"ü§ñ Modelo escolhido: {modelo_escolhido}")

        # Gera a resposta da IA
        resposta = openai.ChatCompletion.create(
            model=modelo_escolhido,
            messages=chat_history
        )

        if not resposta or not resposta.choices or not resposta.choices[0].message:
            print("‚ö†Ô∏è Resposta da IA vazia ou inv√°lida.")
            return "Desculpe, n√£o consegui formular uma resposta agora."

        resposta_texto = resposta.choices[0].message.content.strip()
        print(f"‚úÖ Resposta gerada: {resposta_texto}")

        # Armazena resposta no hist√≥rico
        chat_history.append({"role": "assistant", "content": resposta_texto})

        return resposta_texto

    except Exception as e:
        print("‚ùå Erro ao gerar resposta com OpenAI:")
        traceback.print_exc()
        return "Desculpe, houve um problema ao tentar responder."
