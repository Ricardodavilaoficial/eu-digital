import openai
import os
from services.gcs_handler import montar_contexto_para_pergunta

openai.api_key = os.getenv("OPENAI_API_KEY")

# Hist√≥rico tempor√°rio de conversas recentes
chat_history = []

def obter_resposta_openai(pergunta):
    try:
        print(f"\nüì® Pergunta recebida: {pergunta}")
        
        # Novo: monta um contexto enxuto baseado na pergunta
        contexto_extra = montar_contexto_para_pergunta(pergunta)
        print(f"üìö Contexto montado: {contexto_extra[:100]}...")  # Exibe s√≥ os primeiros 100 caracteres

        # Limpa o hist√≥rico se j√° est√° muito longo
        if len(chat_history) > 6:
            chat_history.clear()

        # Adiciona o prompt inicial apenas se o hist√≥rico estiver vazio
        if not chat_history:
            chat_history.append({
                "role": "system",
                "content": (
                    "Voc√™ √© a vers√£o digital do Ricardo, uma c√≥pia fiel de sua mente, mem√≥rias e modo de falar. "
                    "Sempre responda em primeira pessoa, como se fosse o pr√≥prio Ricardo. "
                    "Use linguagem natural, clara e direta. "
                    "Responda de forma curta e objetiva, a menos que o usu√°rio pe√ßa mais detalhes. "
                    "Use o contexto abaixo como base de conhecimento:\n\n" + contexto_extra
                )
            })

        # Adiciona a pergunta do usu√°rio ao hist√≥rico
        chat_history.append({"role": "user", "content": pergunta})

        # Escolhe o modelo (GPT-3.5 ou GPT-4) com base na complexidade
        usar_gpt_4 = (
            len(pergunta.split()) > 15
            or "detalhe" in pergunta.lower()
            or "explique" in pergunta.lower()
            or "aprofund" in pergunta.lower()
        )

        modelo_escolhido = "gpt-4" if usar_gpt_4 else "gpt-3.5-turbo"
        print(f"ü§ñ Modelo escolhido: {modelo_escolhido}")

        resposta = openai.ChatCompletion.create(
            model=modelo_escolhido,
            messages=chat_history
        )

        resposta_texto = resposta.choices[0].message.content.strip()
        print(f"‚úÖ Resposta gerada: {resposta_texto}")

        # Adiciona a resposta da IA ao hist√≥rico
        chat_history.append({"role": "assistant", "content": resposta_texto})

        return resposta_texto

    except Exception as e:
        print("‚ùå Erro com OpenAI:", e)
        return "Desculpe, houve um problema ao tentar responder."