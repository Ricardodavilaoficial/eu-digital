from flask import Blueprint, request, send_file, jsonify
from services.audio_processing import transcrever_audio_google
from services.openai_handler import obter_resposta_openai
from services.text_to_speech import gerar_audio_elevenlabs
from interfaces.web_interface import html_index
import uuid
from pydub import AudioSegment
import traceback
import os

routes = Blueprint("routes", __name__)

# PÃ¡gina inicial renderizada pela interface HTML (usada em testes locais ou debug)
@routes.route("/", methods=["GET"])
def index():
    return html_index()

# Rota para processar um Ã¡udio recebido (ex: do WhatsApp ou formulÃ¡rio)
@routes.route("/audio", methods=["POST"])
def processar_audio():
    try:
        print("ğŸ“¥ POST /audio recebido")
        print("ğŸ” request.files:", request.files)
        print("ğŸ” request.form:", request.form)
        print("ğŸ” request.content_type:", request.content_type)
        print("ğŸ” request.mimetype:", request.mimetype)
        print("ğŸ” request.headers:", request.headers)

        # Verifica se veio algum arquivo chamado 'audio' no form-data
        if 'audio' not in request.files:
            print("ğŸš« Campo 'audio' nÃ£o encontrado em request.files")
            return jsonify({"error": "Campo 'audio' nÃ£o encontrado no form-data"}), 400

        audio_file = request.files['audio']

        if audio_file.filename == "":
            print("ğŸš« Nome de arquivo vazio")
            return jsonify({"error": "Arquivo de Ã¡udio invÃ¡lido"}), 400

        # Gera caminho Ãºnico e temporÃ¡rio para salvar o Ã¡udio
        unique_id = str(uuid.uuid4())
        caminho_original = f"/tmp/{unique_id}.webm"
        caminho_wav = f"/tmp/{unique_id}.wav"
        audio_file.save(caminho_original)
        print(f"ğŸ’¾ Ãudio salvo em: {caminho_original}")

        # Converte para WAV com padrÃ£o ideal para STT
        print("ğŸ”„ Convertendo .webm para .wav")
        audio = AudioSegment.from_file(caminho_original)
        audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
        audio.export(caminho_wav, format="wav")
        print(f"âœ… ConversÃ£o concluÃ­da: {caminho_wav}")

        # Transcreve o Ã¡udio com Google STT
        print("ğŸ“ Transcrevendo Ã¡udio...")
        texto = transcrever_audio_google(caminho_wav)
        print(f"ğŸ“„ Texto transcrito: '{texto}'")

        if not texto or len(texto.strip()) == 0:
            print("âš ï¸ TranscriÃ§Ã£o vazia ou falhou.")
            return jsonify({"error": "NÃ£o foi possÃ­vel transcrever o Ã¡udio"}), 400

        # Gera resposta via OpenAI
        resposta = obter_resposta_openai(texto)
        print(f"ğŸ¤– Resposta da IA: '{resposta}'")

        # Converte a resposta em Ã¡udio (voz clonada do cliente)
        caminho_audio_resposta = gerar_audio_elevenlabs(resposta)
        print(f"ğŸ”Š Caminho do Ã¡udio gerado: {caminho_audio_resposta}")

        # Retorna o Ã¡udio para o frontend
        return send_file(caminho_audio_resposta, mimetype="audio/mpeg")

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": f"Erro interno: {str(e)}"}), 500
